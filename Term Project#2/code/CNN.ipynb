{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder\n",
    "import keras #library for neural network\n",
    "import pandas as pd #loading data in table form  \n",
    "import seaborn as sns #visualisation \n",
    "import matplotlib.pyplot as plt #visualisation\n",
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "from sklearn.preprocessing import normalize #machine learning algorithm library\n",
    "from sklearn.model_selection import train_test_split\n",
    "from tensorflow import keras\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report,confusion_matrix\n",
    "from sklearn.utils import shuffle\n",
    "\n",
    "preprocess_status = '_std_over_median' # read csv file name and save model file name"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read train dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LOS</th>\n",
       "      <th>Joint</th>\n",
       "      <th>Drain</th>\n",
       "      <th>Cemented</th>\n",
       "      <th>Commercial_ALBC</th>\n",
       "      <th>Non_commercial_ALBC</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>elx_index</th>\n",
       "      <th>...</th>\n",
       "      <th>Fluid and Electrolyte Disorders</th>\n",
       "      <th>Blood Loss Anemia</th>\n",
       "      <th>Deficiency Anemia</th>\n",
       "      <th>Anemia</th>\n",
       "      <th>Alcohol Abuse</th>\n",
       "      <th>Drug Abuse</th>\n",
       "      <th>Psychoses</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Psyciatric disorder</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   AGE  SEX   LOS  Joint  Drain  Cemented  Commercial_ALBC  \\\n",
       "0   -1    1  0.82      0      1         1                0   \n",
       "1    0    0 -0.20      0      1         1                1   \n",
       "2    1    0  0.82      0      1         1                0   \n",
       "\n",
       "   Non_commercial_ALBC  cci_index  elx_index  ...  \\\n",
       "0                    1          0          0  ...   \n",
       "1                    0          1          1  ...   \n",
       "2                    1          1          1  ...   \n",
       "\n",
       "   Fluid and Electrolyte Disorders  Blood Loss Anemia  Deficiency Anemia  \\\n",
       "0                                0                  0                  0   \n",
       "1                                0                  0                  0   \n",
       "2                                0                  0                  0   \n",
       "\n",
       "   Anemia  Alcohol Abuse  Drug Abuse  Psychoses  Depression  \\\n",
       "0       0              0           0          0           0   \n",
       "1       0              0           0          0           0   \n",
       "2       0              0           0          0           0   \n",
       "\n",
       "   Psyciatric disorder  outcome  \n",
       "0                    0        1  \n",
       "1                    0        1  \n",
       "2                    0        1  \n",
       "\n",
       "[3 rows x 67 columns]"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr = pd.read_excel(\"./preprocess/output_tr\" + preprocess_status + \".xlsx\", engine='openpyxl')\n",
    "# df = pd.read_csv(\"final/tr.csv\")\n",
    "df_tr.head(3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 696,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(96458, 67)"
      ]
     },
     "execution_count": 696,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## read test dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_ts = pd.read_excel(\"ts.xlsx\", engine='openpyxl')\n",
    "# df = pd.read_csv(\"final/ts.csv\")\n",
    "df_ts.head(3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 資料前處理"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### random row data order"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LOS</th>\n",
       "      <th>Joint</th>\n",
       "      <th>Drain</th>\n",
       "      <th>Cemented</th>\n",
       "      <th>Commercial_ALBC</th>\n",
       "      <th>Non_commercial_ALBC</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>elx_index</th>\n",
       "      <th>...</th>\n",
       "      <th>Fluid and Electrolyte Disorders</th>\n",
       "      <th>Blood Loss Anemia</th>\n",
       "      <th>Deficiency Anemia</th>\n",
       "      <th>Anemia</th>\n",
       "      <th>Alcohol Abuse</th>\n",
       "      <th>Drug Abuse</th>\n",
       "      <th>Psychoses</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Psyciatric disorder</th>\n",
       "      <th>outcome</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>72121</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>82120</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.94</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24767</th>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>-1.22</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>90264</th>\n",
       "      <td>-2</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1340</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>78003</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25439</th>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14831</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1.50</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>83654</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1.26</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11618</th>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>96458 rows × 67 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX   LOS  Joint  Drain  Cemented  Commercial_ALBC  \\\n",
       "72121    0    1  0.62      0      1         1                0   \n",
       "82120    1    1  1.94      0      1         1                0   \n",
       "24767   -1    0 -1.22      1      0         0                0   \n",
       "90264   -2    0 -0.20      1      0         0                0   \n",
       "1340     0    1  0.48      0      1         1                0   \n",
       "...    ...  ...   ...    ...    ...       ...              ...   \n",
       "78003    1    1 -0.20      0      0         1                0   \n",
       "25439    0    1  0.14      1      1         1                0   \n",
       "14831    1    1  1.50      0      1         1                0   \n",
       "83654    0    0  1.26      0      1         1                0   \n",
       "11618    1    0 -0.20      0      0         1                0   \n",
       "\n",
       "       Non_commercial_ALBC  cci_index  elx_index  ...  \\\n",
       "72121                    1          1          2  ...   \n",
       "82120                    1          1          2  ...   \n",
       "24767                    0          0          0  ...   \n",
       "90264                    0          0          0  ...   \n",
       "1340                     1          0          0  ...   \n",
       "...                    ...        ...        ...  ...   \n",
       "78003                    1          0          1  ...   \n",
       "25439                    1          0          1  ...   \n",
       "14831                    1          0          1  ...   \n",
       "83654                    1          0          0  ...   \n",
       "11618                    1          1          1  ...   \n",
       "\n",
       "       Fluid and Electrolyte Disorders  Blood Loss Anemia  Deficiency Anemia  \\\n",
       "72121                                0                  0                  0   \n",
       "82120                                0                  0                  0   \n",
       "24767                                0                  0                  0   \n",
       "90264                                0                  0                  0   \n",
       "1340                                 0                  0                  0   \n",
       "...                                ...                ...                ...   \n",
       "78003                                0                  0                  0   \n",
       "25439                                0                  0                  0   \n",
       "14831                                0                  0                  0   \n",
       "83654                                0                  0                  0   \n",
       "11618                                0                  0                  0   \n",
       "\n",
       "       Anemia  Alcohol Abuse  Drug Abuse  Psychoses  Depression  \\\n",
       "72121       0              0           0          0           0   \n",
       "82120       0              0           0          0           1   \n",
       "24767       0              0           0          0           0   \n",
       "90264       0              0           0          0           0   \n",
       "1340        0              0           0          0           0   \n",
       "...       ...            ...         ...        ...         ...   \n",
       "78003       0              0           0          0           0   \n",
       "25439       0              0           0          0           0   \n",
       "14831       0              0           0          0           0   \n",
       "83654       0              0           0          0           0   \n",
       "11618       0              0           0          0           0   \n",
       "\n",
       "       Psyciatric disorder  outcome  \n",
       "72121                    0        1  \n",
       "82120                    1        1  \n",
       "24767                    0        0  \n",
       "90264                    0        1  \n",
       "1340                     0        0  \n",
       "...                    ...      ...  \n",
       "78003                    0        1  \n",
       "25439                    0        0  \n",
       "14831                    0        0  \n",
       "83654                    0        1  \n",
       "11618                    0        0  \n",
       "\n",
       "[96458 rows x 67 columns]"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_tr_shuffle = shuffle(df_tr)\n",
    "df_tr_shuffle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 切割data and label"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_tr_shuffle.drop('outcome', 1) # data\n",
    "y = df_tr_shuffle['outcome'] # label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1 1 0 ... 0 1 0]\n"
     ]
    }
   ],
   "source": [
    "# Convert target into LabelEncoder\n",
    "encoder =  LabelEncoder()\n",
    "y1 = encoder.fit_transform(y)\n",
    "print(y1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[0 1]\n",
      " [0 1]\n",
      " [1 0]\n",
      " [0 1]\n",
      " [1 0]]\n"
     ]
    }
   ],
   "source": [
    "# Convert target into one hot encoding\n",
    "Y = pd.get_dummies(y1).values\n",
    "print(Y[0:5])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 將資料分成訓練組及測試組"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one hot format\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, Y,test_size=0.2,random_state=42)\n",
    "\n",
    "# label format\n",
    "X_train_org, X_test_org, y_train_org, y_test_org = train_test_split(X, y,test_size=0.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LOS</th>\n",
       "      <th>Joint</th>\n",
       "      <th>Drain</th>\n",
       "      <th>Cemented</th>\n",
       "      <th>Commercial_ALBC</th>\n",
       "      <th>Non_commercial_ALBC</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>elx_index</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight Loss</th>\n",
       "      <th>Fluid and Electrolyte Disorders</th>\n",
       "      <th>Blood Loss Anemia</th>\n",
       "      <th>Deficiency Anemia</th>\n",
       "      <th>Anemia</th>\n",
       "      <th>Alcohol Abuse</th>\n",
       "      <th>Drug Abuse</th>\n",
       "      <th>Psychoses</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Psyciatric disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60720</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65330</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51751</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX   LOS  Joint  Drain  Cemented  Commercial_ALBC  \\\n",
       "60720    1    1  0.82      0      1         1                0   \n",
       "9940     1    1  0.14      0      1         1                0   \n",
       "65330    0    0  0.48      1      1         0                0   \n",
       "73838    0    0 -0.89      0      1         1                0   \n",
       "51751   -1    1 -0.20      0      0         0                0   \n",
       "\n",
       "       Non_commercial_ALBC  cci_index  elx_index  ...  Weight Loss  \\\n",
       "60720                    1          1          1  ...            0   \n",
       "9940                     1          1          1  ...            0   \n",
       "65330                    0          0          0  ...            0   \n",
       "73838                    1          0          1  ...            0   \n",
       "51751                    0          0          2  ...            0   \n",
       "\n",
       "       Fluid and Electrolyte Disorders  Blood Loss Anemia  Deficiency Anemia  \\\n",
       "60720                                0                  0                  0   \n",
       "9940                                 0                  0                  0   \n",
       "65330                                0                  0                  0   \n",
       "73838                                0                  0                  0   \n",
       "51751                                0                  0                  0   \n",
       "\n",
       "       Anemia  Alcohol Abuse  Drug Abuse  Psychoses  Depression  \\\n",
       "60720       0              0           0          0           0   \n",
       "9940        0              0           0          0           0   \n",
       "65330       0              0           0          0           0   \n",
       "73838       0              0           0          0           0   \n",
       "51751       0              0           0          0           0   \n",
       "\n",
       "       Psyciatric disorder  \n",
       "60720                    0  \n",
       "9940                     0  \n",
       "65330                    0  \n",
       "73838                    0  \n",
       "51751                    0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1],\n",
       "       [1, 0],\n",
       "       [0, 1],\n",
       "       [0, 1],\n",
       "       [0, 1]], dtype=uint8)"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>AGE</th>\n",
       "      <th>SEX</th>\n",
       "      <th>LOS</th>\n",
       "      <th>Joint</th>\n",
       "      <th>Drain</th>\n",
       "      <th>Cemented</th>\n",
       "      <th>Commercial_ALBC</th>\n",
       "      <th>Non_commercial_ALBC</th>\n",
       "      <th>cci_index</th>\n",
       "      <th>elx_index</th>\n",
       "      <th>...</th>\n",
       "      <th>Weight Loss</th>\n",
       "      <th>Fluid and Electrolyte Disorders</th>\n",
       "      <th>Blood Loss Anemia</th>\n",
       "      <th>Deficiency Anemia</th>\n",
       "      <th>Anemia</th>\n",
       "      <th>Alcohol Abuse</th>\n",
       "      <th>Drug Abuse</th>\n",
       "      <th>Psychoses</th>\n",
       "      <th>Depression</th>\n",
       "      <th>Psyciatric disorder</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>60720</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.82</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9940</th>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0.14</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65330</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0.48</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>73838</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>-0.89</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>51751</th>\n",
       "      <td>-1</td>\n",
       "      <td>1</td>\n",
       "      <td>-0.20</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 66 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       AGE  SEX   LOS  Joint  Drain  Cemented  Commercial_ALBC  \\\n",
       "60720    1    1  0.82      0      1         1                0   \n",
       "9940     1    1  0.14      0      1         1                0   \n",
       "65330    0    0  0.48      1      1         0                0   \n",
       "73838    0    0 -0.89      0      1         1                0   \n",
       "51751   -1    1 -0.20      0      0         0                0   \n",
       "\n",
       "       Non_commercial_ALBC  cci_index  elx_index  ...  Weight Loss  \\\n",
       "60720                    1          1          1  ...            0   \n",
       "9940                     1          1          1  ...            0   \n",
       "65330                    0          0          0  ...            0   \n",
       "73838                    1          0          1  ...            0   \n",
       "51751                    0          0          2  ...            0   \n",
       "\n",
       "       Fluid and Electrolyte Disorders  Blood Loss Anemia  Deficiency Anemia  \\\n",
       "60720                                0                  0                  0   \n",
       "9940                                 0                  0                  0   \n",
       "65330                                0                  0                  0   \n",
       "73838                                0                  0                  0   \n",
       "51751                                0                  0                  0   \n",
       "\n",
       "       Anemia  Alcohol Abuse  Drug Abuse  Psychoses  Depression  \\\n",
       "60720       0              0           0          0           0   \n",
       "9940        0              0           0          0           0   \n",
       "65330       0              0           0          0           0   \n",
       "73838       0              0           0          0           0   \n",
       "51751       0              0           0          0           0   \n",
       "\n",
       "       Psyciatric disorder  \n",
       "60720                    0  \n",
       "9940                     0  \n",
       "65330                    0  \n",
       "73838                    0  \n",
       "51751                    0  \n",
       "\n",
       "[5 rows x 66 columns]"
      ]
     },
     "execution_count": 84,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train_org[0:5]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "60720    1\n",
       "9940     0\n",
       "65330    1\n",
       "73838    1\n",
       "51751    1\n",
       "Name: outcome, dtype: int64"
      ]
     },
     "execution_count": 85,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train_org[0:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CNN"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 載入套件"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense,Dropout,Conv1D,MaxPool1D,Flatten,AveragePooling1D,GlobalAveragePooling1D\n",
    "from tensorflow.keras.optimizers import Adam"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2D convert to 3D"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tf.Tensor([77166     1    66], shape=(3,), dtype=int32)\n",
      "tf.Tensor([19292     1    66], shape=(3,), dtype=int32)\n"
     ]
    }
   ],
   "source": [
    "X_train_3D = tf.expand_dims(X_train, axis=1)\n",
    "print(tf.shape(X_train_3D))\n",
    "X_test_3D = tf.expand_dims(X_test, axis=1)\n",
    "print(tf.shape(X_test_3D))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_timesteps, n_features, n_outputs = X_train_3D.shape[1], X_train_3D.shape[2], y_train.shape[1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Define a model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 153,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第一種 基本款\n",
    "model = tf.keras.Sequential([\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(10, activation='relu'),\n",
    "    tf.keras.layers.Dense(2)\n",
    "  ])\n",
    "\n",
    "# Compile the model\n",
    "model.compile(optimizer='rmsprop',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第二種 2層Conv\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=1, kernel_size=6, strides=1, padding='same', activation='relu', input_shape = (n_timesteps,n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(pool_size=1))\n",
    "model.add(Conv1D(6, 16, strides=1, padding='same', activation='relu'))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(100, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第三種 3層Conv\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=1, kernel_size=6, strides=1, padding='same', activation='relu', input_shape = (n_timesteps,n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(pool_size=1))\n",
    "model.add(Conv1D(filters=1, kernel_size=6, strides=1, padding='same', activation='relu', input_shape = (n_timesteps,n_features)))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(MaxPool1D(pool_size=1))\n",
    "model.add(Conv1D(6, 16, strides=1, padding='same', activation='relu'))\n",
    "model.add(MaxPool1D(pool_size=1))\n",
    "model.add(Dropout(0.2))\n",
    "model.add(Flatten())\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(10, activation='relu'))\n",
    "model.add(Dense(n_outputs, activation='softmax'))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第四種 1層Conv\n",
    "model=Sequential()\n",
    "\n",
    "model.add(Conv1D(filters=1, kernel_size=6, strides=1, padding='same', activation='tanh', input_shape = (n_timesteps,n_features), name=\"Conv1\"))\n",
    "model.add(MaxPool1D(pool_size=1, name=\"Pool1\"))\n",
    "model.add(Flatten(name=\"Flatten1\"))\n",
    "model.add(Dropout(0.2, name=\"Dropout1\"))\n",
    "model.add(Dense(10, activation='relu', name=\"Dense1\"))\n",
    "model.add(Dense(10, activation='relu', name=\"Dense2\"))\n",
    "model.add(keras.layers.BatchNormalization(name=\"BN1\"))\n",
    "model.add(Dense(n_outputs, activation='softmax', name=\"Dense3\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='sgd',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 第五種 AutoML生成的\n",
    "model=Sequential()\n",
    "\n",
    "model.add(tf.keras.layers.experimental.preprocessing.Normalization(name=\"Normal1\"))\n",
    "model.add(Dense(256, activation='relu', name=\"Dense1\"))\n",
    "model.add(tf.keras.layers.ReLU(256, name=\"ReLU1\"))\n",
    "model.add(Dense(32, activation='relu', name=\"Dense2\"))\n",
    "model.add(tf.keras.layers.ReLU(32, name=\"ReLU2\"))\n",
    "model.add(Dense(n_outputs, activation='softmax', name=\"Dense3\"))\n",
    "\n",
    "# Compile the model\n",
    "model.compile(loss='categorical_crossentropy',optimizer='adam',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### callbacks setting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train the model\n",
    "ACCURACY_THRESHOLD = 0.95\n",
    "# Implement callback function to stop training\n",
    "# when accuracy reaches e.g. ACCURACY_THRESHOLD = 0.95\n",
    "class myCallback(tf.keras.callbacks.Callback): \n",
    "    def on_epoch_end(self, epoch, logs={}): \n",
    "        if(logs.get('val_accuracy') > ACCURACY_THRESHOLD):   \n",
    "            print(\"\\nReached %2.2f%% accuracy, so stopping training!!\" %(ACCURACY_THRESHOLD*100))   \n",
    "            self.model.stop_training = True\n",
    "callback = myCallback()\n",
    "# callback = tf.keras.callbacks.EarlyStopping(monitor='val_accuracy', patience=100, mode='max')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  fit model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### no weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/1000\n",
      "58/58 [==============================] - 1s 12ms/step - loss: 0.6080 - accuracy: 0.6591 - val_loss: 0.4753 - val_accuracy: 0.7687\n",
      "Epoch 2/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.4494 - accuracy: 0.7833 - val_loss: 0.3980 - val_accuracy: 0.8129\n",
      "Epoch 3/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.3843 - accuracy: 0.8210 - val_loss: 0.3557 - val_accuracy: 0.8329\n",
      "Epoch 4/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3451 - accuracy: 0.8396 - val_loss: 0.3329 - val_accuracy: 0.8455\n",
      "Epoch 5/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.3133 - accuracy: 0.8582 - val_loss: 0.3127 - val_accuracy: 0.8599\n",
      "Epoch 6/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.2938 - accuracy: 0.8711 - val_loss: 0.2975 - val_accuracy: 0.8674\n",
      "Epoch 7/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.2800 - accuracy: 0.8772 - val_loss: 0.2820 - val_accuracy: 0.8772\n",
      "Epoch 8/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.2579 - accuracy: 0.8905 - val_loss: 0.2708 - val_accuracy: 0.8881\n",
      "Epoch 9/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.2479 - accuracy: 0.8983 - val_loss: 0.2644 - val_accuracy: 0.8915\n",
      "Epoch 10/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.2382 - accuracy: 0.8997 - val_loss: 0.2574 - val_accuracy: 0.8925\n",
      "Epoch 11/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.2336 - accuracy: 0.9045 - val_loss: 0.2547 - val_accuracy: 0.8946\n",
      "Epoch 12/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.2285 - accuracy: 0.9066 - val_loss: 0.2421 - val_accuracy: 0.9031\n",
      "Epoch 13/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.2148 - accuracy: 0.9125 - val_loss: 0.2395 - val_accuracy: 0.9033\n",
      "Epoch 14/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.2063 - accuracy: 0.9174 - val_loss: 0.2331 - val_accuracy: 0.9079\n",
      "Epoch 15/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.2044 - accuracy: 0.9179 - val_loss: 0.2286 - val_accuracy: 0.9094\n",
      "Epoch 16/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1972 - accuracy: 0.9208 - val_loss: 0.2344 - val_accuracy: 0.9081\n",
      "Epoch 17/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1905 - accuracy: 0.9239 - val_loss: 0.2292 - val_accuracy: 0.9100\n",
      "Epoch 18/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1877 - accuracy: 0.9257 - val_loss: 0.2205 - val_accuracy: 0.9144\n",
      "Epoch 19/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1827 - accuracy: 0.9279 - val_loss: 0.2234 - val_accuracy: 0.9151\n",
      "Epoch 20/1000\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.1848 - accuracy: 0.9250 - val_loss: 0.2168 - val_accuracy: 0.9173\n",
      "Epoch 21/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1788 - accuracy: 0.9292 - val_loss: 0.2168 - val_accuracy: 0.9186\n",
      "Epoch 22/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1754 - accuracy: 0.9311 - val_loss: 0.2120 - val_accuracy: 0.9205\n",
      "Epoch 23/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1679 - accuracy: 0.9343 - val_loss: 0.2093 - val_accuracy: 0.9225\n",
      "Epoch 24/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1650 - accuracy: 0.9368 - val_loss: 0.2091 - val_accuracy: 0.9214\n",
      "Epoch 25/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1652 - accuracy: 0.9334 - val_loss: 0.2066 - val_accuracy: 0.9233\n",
      "Epoch 26/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1633 - accuracy: 0.9368 - val_loss: 0.2027 - val_accuracy: 0.9250\n",
      "Epoch 27/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1582 - accuracy: 0.9389 - val_loss: 0.2048 - val_accuracy: 0.9250\n",
      "Epoch 28/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1550 - accuracy: 0.9407 - val_loss: 0.2013 - val_accuracy: 0.9264\n",
      "Epoch 29/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1524 - accuracy: 0.9419 - val_loss: 0.2153 - val_accuracy: 0.9183\n",
      "Epoch 30/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1543 - accuracy: 0.9398 - val_loss: 0.1989 - val_accuracy: 0.9273\n",
      "Epoch 31/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1509 - accuracy: 0.9414 - val_loss: 0.1963 - val_accuracy: 0.9298\n",
      "Epoch 32/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1488 - accuracy: 0.9426 - val_loss: 0.1998 - val_accuracy: 0.9271\n",
      "Epoch 33/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1517 - accuracy: 0.9410 - val_loss: 0.1982 - val_accuracy: 0.9305\n",
      "Epoch 34/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1486 - accuracy: 0.9412 - val_loss: 0.2087 - val_accuracy: 0.9244\n",
      "Epoch 35/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1491 - accuracy: 0.9420 - val_loss: 0.1962 - val_accuracy: 0.9282\n",
      "Epoch 36/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1432 - accuracy: 0.9445 - val_loss: 0.1996 - val_accuracy: 0.9287\n",
      "Epoch 37/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1445 - accuracy: 0.9440 - val_loss: 0.1953 - val_accuracy: 0.9329\n",
      "Epoch 38/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1373 - accuracy: 0.9491 - val_loss: 0.1954 - val_accuracy: 0.9324\n",
      "Epoch 39/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1383 - accuracy: 0.9451 - val_loss: 0.1927 - val_accuracy: 0.9321\n",
      "Epoch 40/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1318 - accuracy: 0.9496 - val_loss: 0.1931 - val_accuracy: 0.9328\n",
      "Epoch 41/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1380 - accuracy: 0.9462 - val_loss: 0.1980 - val_accuracy: 0.9321\n",
      "Epoch 42/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1350 - accuracy: 0.9476 - val_loss: 0.1905 - val_accuracy: 0.9342\n",
      "Epoch 43/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1288 - accuracy: 0.9497 - val_loss: 0.1951 - val_accuracy: 0.9328\n",
      "Epoch 44/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1320 - accuracy: 0.9487 - val_loss: 0.2086 - val_accuracy: 0.9289\n",
      "Epoch 45/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1335 - accuracy: 0.9484 - val_loss: 0.2148 - val_accuracy: 0.9258\n",
      "Epoch 46/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1312 - accuracy: 0.9486 - val_loss: 0.1930 - val_accuracy: 0.9339\n",
      "Epoch 47/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1280 - accuracy: 0.9515 - val_loss: 0.1920 - val_accuracy: 0.9341\n",
      "Epoch 48/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1283 - accuracy: 0.9505 - val_loss: 0.1862 - val_accuracy: 0.9397\n",
      "Epoch 49/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1222 - accuracy: 0.9539 - val_loss: 0.1912 - val_accuracy: 0.9360\n",
      "Epoch 50/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1279 - accuracy: 0.9504 - val_loss: 0.1966 - val_accuracy: 0.9338\n",
      "Epoch 51/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1227 - accuracy: 0.9534 - val_loss: 0.2001 - val_accuracy: 0.9250\n",
      "Epoch 52/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1297 - accuracy: 0.9485 - val_loss: 0.1964 - val_accuracy: 0.9357\n",
      "Epoch 53/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1228 - accuracy: 0.9529 - val_loss: 0.1929 - val_accuracy: 0.9343\n",
      "Epoch 54/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1232 - accuracy: 0.9534 - val_loss: 0.1956 - val_accuracy: 0.9354\n",
      "Epoch 55/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1173 - accuracy: 0.9557 - val_loss: 0.1943 - val_accuracy: 0.9355\n",
      "Epoch 56/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9529 - val_loss: 0.1931 - val_accuracy: 0.9358\n",
      "Epoch 57/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1208 - accuracy: 0.9537 - val_loss: 0.2053 - val_accuracy: 0.9335\n",
      "Epoch 58/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1177 - accuracy: 0.9543 - val_loss: 0.1895 - val_accuracy: 0.9396\n",
      "Epoch 59/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1156 - accuracy: 0.9557 - val_loss: 0.1904 - val_accuracy: 0.9384\n",
      "Epoch 60/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1169 - accuracy: 0.9551 - val_loss: 0.2066 - val_accuracy: 0.9354\n",
      "Epoch 61/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1185 - accuracy: 0.9544 - val_loss: 0.2049 - val_accuracy: 0.9345\n",
      "Epoch 62/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1223 - accuracy: 0.9532 - val_loss: 0.1977 - val_accuracy: 0.9339\n",
      "Epoch 63/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1186 - accuracy: 0.9552 - val_loss: 0.1987 - val_accuracy: 0.9352\n",
      "Epoch 64/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1202 - accuracy: 0.9529 - val_loss: 0.1917 - val_accuracy: 0.9377\n",
      "Epoch 65/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1170 - accuracy: 0.9548 - val_loss: 0.1921 - val_accuracy: 0.9381\n",
      "Epoch 66/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.9556 - val_loss: 0.1898 - val_accuracy: 0.9383\n",
      "Epoch 67/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1164 - accuracy: 0.9541 - val_loss: 0.1886 - val_accuracy: 0.9405\n",
      "Epoch 68/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1133 - accuracy: 0.9567 - val_loss: 0.1931 - val_accuracy: 0.9383\n",
      "Epoch 69/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1157 - accuracy: 0.9540 - val_loss: 0.2084 - val_accuracy: 0.9325\n",
      "Epoch 70/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1148 - accuracy: 0.9554 - val_loss: 0.1929 - val_accuracy: 0.9370\n",
      "Epoch 71/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1153 - accuracy: 0.9550 - val_loss: 0.1975 - val_accuracy: 0.9377\n",
      "Epoch 72/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1176 - accuracy: 0.9538 - val_loss: 0.1919 - val_accuracy: 0.9396\n",
      "Epoch 73/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1105 - accuracy: 0.9573 - val_loss: 0.1845 - val_accuracy: 0.9425\n",
      "Epoch 74/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1076 - accuracy: 0.9591 - val_loss: 0.1952 - val_accuracy: 0.9390\n",
      "Epoch 75/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1098 - accuracy: 0.9583 - val_loss: 0.1941 - val_accuracy: 0.9367\n",
      "Epoch 76/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1109 - accuracy: 0.9569 - val_loss: 0.1947 - val_accuracy: 0.9369\n",
      "Epoch 77/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9561 - val_loss: 0.1936 - val_accuracy: 0.9383\n",
      "Epoch 78/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9570 - val_loss: 0.1975 - val_accuracy: 0.9374\n",
      "Epoch 79/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9581 - val_loss: 0.1909 - val_accuracy: 0.9402\n",
      "Epoch 80/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1062 - accuracy: 0.9584 - val_loss: 0.1979 - val_accuracy: 0.9392\n",
      "Epoch 81/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1098 - accuracy: 0.9565 - val_loss: 0.2091 - val_accuracy: 0.9357\n",
      "Epoch 82/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1162 - accuracy: 0.9534 - val_loss: 0.1960 - val_accuracy: 0.9418\n",
      "Epoch 83/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1072 - accuracy: 0.9583 - val_loss: 0.2021 - val_accuracy: 0.9367\n",
      "Epoch 84/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1066 - accuracy: 0.9587 - val_loss: 0.1915 - val_accuracy: 0.9428\n",
      "Epoch 85/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1045 - accuracy: 0.9590 - val_loss: 0.1986 - val_accuracy: 0.9404\n",
      "Epoch 86/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1047 - accuracy: 0.9598 - val_loss: 0.1921 - val_accuracy: 0.9401\n",
      "Epoch 87/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9586 - val_loss: 0.1895 - val_accuracy: 0.9432\n",
      "Epoch 88/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.1021 - accuracy: 0.9610 - val_loss: 0.1913 - val_accuracy: 0.9440\n",
      "Epoch 89/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1023 - accuracy: 0.9605 - val_loss: 0.1952 - val_accuracy: 0.9417\n",
      "Epoch 90/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1025 - accuracy: 0.9595 - val_loss: 0.1990 - val_accuracy: 0.9403\n",
      "Epoch 91/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9599 - val_loss: 0.1970 - val_accuracy: 0.9405\n",
      "Epoch 92/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1003 - accuracy: 0.9617 - val_loss: 0.1935 - val_accuracy: 0.9409\n",
      "Epoch 93/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1043 - accuracy: 0.9602 - val_loss: 0.1947 - val_accuracy: 0.9413\n",
      "Epoch 94/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1045 - accuracy: 0.9592 - val_loss: 0.2000 - val_accuracy: 0.9368\n",
      "Epoch 95/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1099 - accuracy: 0.9573 - val_loss: 0.1987 - val_accuracy: 0.9413\n",
      "Epoch 96/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1055 - accuracy: 0.9578 - val_loss: 0.1960 - val_accuracy: 0.9419\n",
      "Epoch 97/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1053 - accuracy: 0.9593 - val_loss: 0.1970 - val_accuracy: 0.9429\n",
      "Epoch 98/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9608 - val_loss: 0.1973 - val_accuracy: 0.9424\n",
      "Epoch 99/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0995 - accuracy: 0.9612 - val_loss: 0.1946 - val_accuracy: 0.9408\n",
      "Epoch 100/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9610 - val_loss: 0.2092 - val_accuracy: 0.9377\n",
      "Epoch 101/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1008 - accuracy: 0.9604 - val_loss: 0.2109 - val_accuracy: 0.9363\n",
      "Epoch 102/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1082 - accuracy: 0.9569 - val_loss: 0.2017 - val_accuracy: 0.9406\n",
      "Epoch 103/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0999 - accuracy: 0.9614 - val_loss: 0.2052 - val_accuracy: 0.9403\n",
      "Epoch 104/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0983 - accuracy: 0.9606 - val_loss: 0.1949 - val_accuracy: 0.9429\n",
      "Epoch 105/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0953 - accuracy: 0.9639 - val_loss: 0.1964 - val_accuracy: 0.9429\n",
      "Epoch 106/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0970 - accuracy: 0.9629 - val_loss: 0.2184 - val_accuracy: 0.9359\n",
      "Epoch 107/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1001 - accuracy: 0.9604 - val_loss: 0.1924 - val_accuracy: 0.9447\n",
      "Epoch 108/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1002 - accuracy: 0.9618 - val_loss: 0.2011 - val_accuracy: 0.9400\n",
      "Epoch 109/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9596 - val_loss: 0.2165 - val_accuracy: 0.9376\n",
      "Epoch 110/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1063 - accuracy: 0.9580 - val_loss: 0.1889 - val_accuracy: 0.9447\n",
      "Epoch 111/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9603 - val_loss: 0.1951 - val_accuracy: 0.9432\n",
      "Epoch 112/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1025 - accuracy: 0.9599 - val_loss: 0.2201 - val_accuracy: 0.9352\n",
      "Epoch 113/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1022 - accuracy: 0.9604 - val_loss: 0.2057 - val_accuracy: 0.9414\n",
      "Epoch 114/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9600 - val_loss: 0.1986 - val_accuracy: 0.9425\n",
      "Epoch 115/1000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1035 - accuracy: 0.9603 - val_loss: 0.1973 - val_accuracy: 0.9404\n",
      "Epoch 116/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0982 - accuracy: 0.9604 - val_loss: 0.2115 - val_accuracy: 0.9388\n",
      "Epoch 117/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1016 - accuracy: 0.9606 - val_loss: 0.1977 - val_accuracy: 0.9428\n",
      "Epoch 118/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0926 - accuracy: 0.9644 - val_loss: 0.1947 - val_accuracy: 0.9442\n",
      "Epoch 119/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0933 - accuracy: 0.9638 - val_loss: 0.1931 - val_accuracy: 0.9447\n",
      "Epoch 120/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0918 - accuracy: 0.9650 - val_loss: 0.1998 - val_accuracy: 0.9439\n",
      "Epoch 121/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0939 - accuracy: 0.9639 - val_loss: 0.2055 - val_accuracy: 0.9379\n",
      "Epoch 122/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0991 - accuracy: 0.9617 - val_loss: 0.1947 - val_accuracy: 0.9446\n",
      "Epoch 123/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0949 - accuracy: 0.9631 - val_loss: 0.2110 - val_accuracy: 0.9405\n",
      "Epoch 124/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1008 - accuracy: 0.9608 - val_loss: 0.2014 - val_accuracy: 0.9437\n",
      "Epoch 125/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0922 - accuracy: 0.9640 - val_loss: 0.2021 - val_accuracy: 0.9452\n",
      "Epoch 126/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0966 - accuracy: 0.9629 - val_loss: 0.2025 - val_accuracy: 0.9453\n",
      "Epoch 127/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0908 - accuracy: 0.9646 - val_loss: 0.2047 - val_accuracy: 0.9436\n",
      "Epoch 128/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0965 - accuracy: 0.9625 - val_loss: 0.2029 - val_accuracy: 0.9423\n",
      "Epoch 129/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9606 - val_loss: 0.1993 - val_accuracy: 0.9448\n",
      "Epoch 130/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0987 - accuracy: 0.9618 - val_loss: 0.2354 - val_accuracy: 0.9367\n",
      "Epoch 131/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9625 - val_loss: 0.2180 - val_accuracy: 0.9397\n",
      "Epoch 132/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1029 - accuracy: 0.9610 - val_loss: 0.2111 - val_accuracy: 0.9432\n",
      "Epoch 133/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0957 - accuracy: 0.9630 - val_loss: 0.2071 - val_accuracy: 0.9425\n",
      "Epoch 134/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.1010 - accuracy: 0.9605 - val_loss: 0.2000 - val_accuracy: 0.9450\n",
      "Epoch 135/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0904 - accuracy: 0.9649 - val_loss: 0.2087 - val_accuracy: 0.9349\n",
      "Epoch 136/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0960 - accuracy: 0.9621 - val_loss: 0.2043 - val_accuracy: 0.9444\n",
      "Epoch 137/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0946 - accuracy: 0.9628 - val_loss: 0.2134 - val_accuracy: 0.9427\n",
      "Epoch 138/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0895 - accuracy: 0.9660 - val_loss: 0.2041 - val_accuracy: 0.9441\n",
      "Epoch 139/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9656 - val_loss: 0.2090 - val_accuracy: 0.9430\n",
      "Epoch 140/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0954 - accuracy: 0.9623 - val_loss: 0.2059 - val_accuracy: 0.9428\n",
      "Epoch 141/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9642 - val_loss: 0.2132 - val_accuracy: 0.9413\n",
      "Epoch 142/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0900 - accuracy: 0.9644 - val_loss: 0.2123 - val_accuracy: 0.9433\n",
      "Epoch 143/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0948 - accuracy: 0.9640 - val_loss: 0.2067 - val_accuracy: 0.9435\n",
      "Epoch 144/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0926 - accuracy: 0.9637 - val_loss: 0.2038 - val_accuracy: 0.9455\n",
      "Epoch 145/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0868 - accuracy: 0.9675 - val_loss: 0.2067 - val_accuracy: 0.9452\n",
      "Epoch 146/1000\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0919 - accuracy: 0.9632 - val_loss: 0.2018 - val_accuracy: 0.9457\n",
      "Epoch 147/1000\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0910 - accuracy: 0.9648 - val_loss: 0.2057 - val_accuracy: 0.9444\n",
      "Epoch 148/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0871 - accuracy: 0.9664 - val_loss: 0.2064 - val_accuracy: 0.9419\n",
      "Epoch 149/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0940 - accuracy: 0.9631 - val_loss: 0.2045 - val_accuracy: 0.9462\n",
      "Epoch 150/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0917 - accuracy: 0.9646 - val_loss: 0.2156 - val_accuracy: 0.9435\n",
      "Epoch 151/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0922 - accuracy: 0.9634 - val_loss: 0.2086 - val_accuracy: 0.9448\n",
      "Epoch 152/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0901 - accuracy: 0.9650 - val_loss: 0.2100 - val_accuracy: 0.9447\n",
      "Epoch 153/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0929 - accuracy: 0.9647 - val_loss: 0.2057 - val_accuracy: 0.9452\n",
      "Epoch 154/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0878 - accuracy: 0.9663 - val_loss: 0.2164 - val_accuracy: 0.9411\n",
      "Epoch 155/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0938 - accuracy: 0.9625 - val_loss: 0.2050 - val_accuracy: 0.9454\n",
      "Epoch 156/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0894 - accuracy: 0.9652 - val_loss: 0.2349 - val_accuracy: 0.9382\n",
      "Epoch 157/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0920 - accuracy: 0.9646 - val_loss: 0.2097 - val_accuracy: 0.9429\n",
      "Epoch 158/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0895 - accuracy: 0.9650 - val_loss: 0.2116 - val_accuracy: 0.9459\n",
      "Epoch 159/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0941 - accuracy: 0.9634 - val_loss: 0.2173 - val_accuracy: 0.9390\n",
      "Epoch 160/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0902 - accuracy: 0.9651 - val_loss: 0.2094 - val_accuracy: 0.9429\n",
      "Epoch 161/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0884 - accuracy: 0.9666 - val_loss: 0.2158 - val_accuracy: 0.9372\n",
      "Epoch 162/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0979 - accuracy: 0.9612 - val_loss: 0.2156 - val_accuracy: 0.9430\n",
      "Epoch 163/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9656 - val_loss: 0.2129 - val_accuracy: 0.9450\n",
      "Epoch 164/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0893 - accuracy: 0.9645 - val_loss: 0.2124 - val_accuracy: 0.9444\n",
      "Epoch 165/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0933 - accuracy: 0.9630 - val_loss: 0.2117 - val_accuracy: 0.9467\n",
      "Epoch 166/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0875 - accuracy: 0.9657 - val_loss: 0.2138 - val_accuracy: 0.9448\n",
      "Epoch 167/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0943 - accuracy: 0.9636 - val_loss: 0.2123 - val_accuracy: 0.9442\n",
      "Epoch 168/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0892 - accuracy: 0.9659 - val_loss: 0.2123 - val_accuracy: 0.9413\n",
      "Epoch 169/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0879 - accuracy: 0.9659 - val_loss: 0.2150 - val_accuracy: 0.9435\n",
      "Epoch 170/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0937 - accuracy: 0.9638 - val_loss: 0.2225 - val_accuracy: 0.9437\n",
      "Epoch 171/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0931 - accuracy: 0.9647 - val_loss: 0.2248 - val_accuracy: 0.9427\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 172/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0896 - accuracy: 0.9650 - val_loss: 0.2131 - val_accuracy: 0.9438\n",
      "Epoch 173/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0869 - accuracy: 0.9662 - val_loss: 0.2172 - val_accuracy: 0.9446\n",
      "Epoch 174/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0914 - accuracy: 0.9629 - val_loss: 0.2261 - val_accuracy: 0.9434\n",
      "Epoch 175/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0906 - accuracy: 0.9645 - val_loss: 0.2323 - val_accuracy: 0.9413\n",
      "Epoch 176/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0923 - accuracy: 0.9637 - val_loss: 0.2215 - val_accuracy: 0.9432\n",
      "Epoch 177/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0864 - accuracy: 0.9656 - val_loss: 0.2124 - val_accuracy: 0.9466\n",
      "Epoch 178/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0859 - accuracy: 0.9673 - val_loss: 0.2080 - val_accuracy: 0.9461\n",
      "Epoch 179/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9661 - val_loss: 0.2210 - val_accuracy: 0.9451\n",
      "Epoch 180/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0839 - accuracy: 0.9673 - val_loss: 0.2535 - val_accuracy: 0.9382\n",
      "Epoch 181/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0929 - accuracy: 0.9642 - val_loss: 0.2141 - val_accuracy: 0.9474\n",
      "Epoch 182/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0866 - accuracy: 0.9660 - val_loss: 0.2137 - val_accuracy: 0.9425\n",
      "Epoch 183/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0887 - accuracy: 0.9647 - val_loss: 0.2158 - val_accuracy: 0.9459\n",
      "Epoch 184/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0848 - accuracy: 0.9673 - val_loss: 0.2228 - val_accuracy: 0.9442\n",
      "Epoch 185/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0811 - accuracy: 0.9688 - val_loss: 0.2192 - val_accuracy: 0.9452\n",
      "Epoch 186/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0842 - accuracy: 0.9677 - val_loss: 0.2129 - val_accuracy: 0.9460\n",
      "Epoch 187/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9688 - val_loss: 0.2169 - val_accuracy: 0.9464\n",
      "Epoch 188/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0867 - accuracy: 0.9660 - val_loss: 0.2130 - val_accuracy: 0.9467\n",
      "Epoch 189/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0862 - accuracy: 0.9664 - val_loss: 0.2143 - val_accuracy: 0.9461\n",
      "Epoch 190/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0838 - accuracy: 0.9682 - val_loss: 0.2514 - val_accuracy: 0.9395\n",
      "Epoch 191/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0918 - accuracy: 0.9644 - val_loss: 0.2364 - val_accuracy: 0.9441\n",
      "Epoch 192/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0910 - accuracy: 0.9640 - val_loss: 0.2256 - val_accuracy: 0.9443\n",
      "Epoch 193/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0846 - accuracy: 0.9677 - val_loss: 0.2125 - val_accuracy: 0.9471\n",
      "Epoch 194/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0881 - accuracy: 0.9662 - val_loss: 0.2319 - val_accuracy: 0.9433\n",
      "Epoch 195/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0866 - accuracy: 0.9661 - val_loss: 0.2519 - val_accuracy: 0.9401\n",
      "Epoch 196/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0913 - accuracy: 0.9637 - val_loss: 0.2218 - val_accuracy: 0.9468\n",
      "Epoch 197/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0924 - accuracy: 0.9642 - val_loss: 0.2555 - val_accuracy: 0.9383\n",
      "Epoch 198/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0960 - accuracy: 0.9630 - val_loss: 0.2728 - val_accuracy: 0.9085\n",
      "Epoch 199/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.1032 - accuracy: 0.9589 - val_loss: 0.2454 - val_accuracy: 0.9407\n",
      "Epoch 200/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0841 - accuracy: 0.9685 - val_loss: 0.2259 - val_accuracy: 0.9450\n",
      "Epoch 201/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0829 - accuracy: 0.9681 - val_loss: 0.2200 - val_accuracy: 0.9460\n",
      "Epoch 202/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0820 - accuracy: 0.9688 - val_loss: 0.2234 - val_accuracy: 0.9466\n",
      "Epoch 203/1000\n",
      "58/58 [==============================] - 1s 9ms/step - loss: 0.0828 - accuracy: 0.9666 - val_loss: 0.2189 - val_accuracy: 0.9454\n",
      "Epoch 204/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9682 - val_loss: 0.2259 - val_accuracy: 0.9461\n",
      "Epoch 205/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0871 - accuracy: 0.9671 - val_loss: 0.2248 - val_accuracy: 0.9458\n",
      "Epoch 206/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0832 - accuracy: 0.9681 - val_loss: 0.2197 - val_accuracy: 0.9464\n",
      "Epoch 207/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0822 - accuracy: 0.9689 - val_loss: 0.2205 - val_accuracy: 0.9468\n",
      "Epoch 208/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0815 - accuracy: 0.9675 - val_loss: 0.2339 - val_accuracy: 0.9430\n",
      "Epoch 209/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0893 - accuracy: 0.9649 - val_loss: 0.2212 - val_accuracy: 0.9461\n",
      "Epoch 210/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9666 - val_loss: 0.2318 - val_accuracy: 0.9424\n",
      "Epoch 211/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0837 - accuracy: 0.9675 - val_loss: 0.2424 - val_accuracy: 0.9422\n",
      "Epoch 212/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0845 - accuracy: 0.9673 - val_loss: 0.2194 - val_accuracy: 0.9470\n",
      "Epoch 213/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0809 - accuracy: 0.9696 - val_loss: 0.2435 - val_accuracy: 0.9420\n",
      "Epoch 214/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0879 - accuracy: 0.9662 - val_loss: 0.2196 - val_accuracy: 0.9467\n",
      "Epoch 215/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0855 - accuracy: 0.9667 - val_loss: 0.2344 - val_accuracy: 0.9440\n",
      "Epoch 216/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0854 - accuracy: 0.9676 - val_loss: 0.2327 - val_accuracy: 0.9448\n",
      "Epoch 217/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0827 - accuracy: 0.9685 - val_loss: 0.2311 - val_accuracy: 0.9447\n",
      "Epoch 218/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0831 - accuracy: 0.9687 - val_loss: 0.2266 - val_accuracy: 0.9463\n",
      "Epoch 219/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9679 - val_loss: 0.2238 - val_accuracy: 0.9465\n",
      "Epoch 220/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0847 - accuracy: 0.9669 - val_loss: 0.2302 - val_accuracy: 0.9438\n",
      "Epoch 221/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0837 - accuracy: 0.9679 - val_loss: 0.2154 - val_accuracy: 0.9488\n",
      "Epoch 222/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0796 - accuracy: 0.9696 - val_loss: 0.2584 - val_accuracy: 0.9395\n",
      "Epoch 223/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0857 - accuracy: 0.9664 - val_loss: 0.2240 - val_accuracy: 0.9463\n",
      "Epoch 224/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9677 - val_loss: 0.2240 - val_accuracy: 0.9472\n",
      "Epoch 225/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0840 - accuracy: 0.9670 - val_loss: 0.2369 - val_accuracy: 0.9426\n",
      "Epoch 226/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0869 - accuracy: 0.9660 - val_loss: 0.2539 - val_accuracy: 0.9395\n",
      "Epoch 227/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0938 - accuracy: 0.9640 - val_loss: 0.2348 - val_accuracy: 0.9437\n",
      "Epoch 228/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0864 - accuracy: 0.9666 - val_loss: 0.2250 - val_accuracy: 0.9466\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 229/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0820 - accuracy: 0.9679 - val_loss: 0.2191 - val_accuracy: 0.9470\n",
      "Epoch 230/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0818 - accuracy: 0.9676 - val_loss: 0.2529 - val_accuracy: 0.9408\n",
      "Epoch 231/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0879 - accuracy: 0.9659 - val_loss: 0.2239 - val_accuracy: 0.9467\n",
      "Epoch 232/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9690 - val_loss: 0.2299 - val_accuracy: 0.9397\n",
      "Epoch 233/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0889 - accuracy: 0.9656 - val_loss: 0.2238 - val_accuracy: 0.9476\n",
      "Epoch 234/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0801 - accuracy: 0.9698 - val_loss: 0.2166 - val_accuracy: 0.9485\n",
      "Epoch 235/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0816 - accuracy: 0.9691 - val_loss: 0.2245 - val_accuracy: 0.9456\n",
      "Epoch 236/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0822 - accuracy: 0.9679 - val_loss: 0.2241 - val_accuracy: 0.9453\n",
      "Epoch 237/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9697 - val_loss: 0.2284 - val_accuracy: 0.9461\n",
      "Epoch 238/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0892 - accuracy: 0.9667 - val_loss: 0.2248 - val_accuracy: 0.9470\n",
      "Epoch 239/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0891 - accuracy: 0.9673 - val_loss: 0.2204 - val_accuracy: 0.9455\n",
      "Epoch 240/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0848 - accuracy: 0.9672 - val_loss: 0.2246 - val_accuracy: 0.9442\n",
      "Epoch 241/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9698 - val_loss: 0.2283 - val_accuracy: 0.9456\n",
      "Epoch 242/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0830 - accuracy: 0.9674 - val_loss: 0.2254 - val_accuracy: 0.9452\n",
      "Epoch 243/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0812 - accuracy: 0.9682 - val_loss: 0.2282 - val_accuracy: 0.9466\n",
      "Epoch 244/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0821 - accuracy: 0.9692 - val_loss: 0.2380 - val_accuracy: 0.9444\n",
      "Epoch 245/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0823 - accuracy: 0.9680 - val_loss: 0.2263 - val_accuracy: 0.9470\n",
      "Epoch 246/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0794 - accuracy: 0.9703 - val_loss: 0.2471 - val_accuracy: 0.9439\n",
      "Epoch 247/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9696 - val_loss: 0.2268 - val_accuracy: 0.9467\n",
      "Epoch 248/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0790 - accuracy: 0.9699 - val_loss: 0.2243 - val_accuracy: 0.9465\n",
      "Epoch 249/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9693 - val_loss: 0.2304 - val_accuracy: 0.9461\n",
      "Epoch 250/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0813 - accuracy: 0.9692 - val_loss: 0.2629 - val_accuracy: 0.9394\n",
      "Epoch 251/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0806 - accuracy: 0.9686 - val_loss: 0.2255 - val_accuracy: 0.9489\n",
      "Epoch 252/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0807 - accuracy: 0.9686 - val_loss: 0.2269 - val_accuracy: 0.9468\n",
      "Epoch 253/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9685 - val_loss: 0.2230 - val_accuracy: 0.9488\n",
      "Epoch 254/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0790 - accuracy: 0.9702 - val_loss: 0.2331 - val_accuracy: 0.9474\n",
      "Epoch 255/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0794 - accuracy: 0.9697 - val_loss: 0.2214 - val_accuracy: 0.9460\n",
      "Epoch 256/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0827 - accuracy: 0.9679 - val_loss: 0.2360 - val_accuracy: 0.9469\n",
      "Epoch 257/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0835 - accuracy: 0.9677 - val_loss: 0.2379 - val_accuracy: 0.9440\n",
      "Epoch 258/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0785 - accuracy: 0.9696 - val_loss: 0.2488 - val_accuracy: 0.9440\n",
      "Epoch 259/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0824 - accuracy: 0.9691 - val_loss: 0.2592 - val_accuracy: 0.9418\n",
      "Epoch 260/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0912 - accuracy: 0.9653 - val_loss: 0.2430 - val_accuracy: 0.9459\n",
      "Epoch 261/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0836 - accuracy: 0.9676 - val_loss: 0.2216 - val_accuracy: 0.9472\n",
      "Epoch 262/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0802 - accuracy: 0.9693 - val_loss: 0.2419 - val_accuracy: 0.9447\n",
      "Epoch 263/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9689 - val_loss: 0.2255 - val_accuracy: 0.9496\n",
      "Epoch 264/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0806 - accuracy: 0.9684 - val_loss: 0.2436 - val_accuracy: 0.9441\n",
      "Epoch 265/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0829 - accuracy: 0.9675 - val_loss: 0.2517 - val_accuracy: 0.9428\n",
      "Epoch 266/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0772 - accuracy: 0.9705 - val_loss: 0.2237 - val_accuracy: 0.9483\n",
      "Epoch 267/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9687 - val_loss: 0.2450 - val_accuracy: 0.9445\n",
      "Epoch 268/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9690 - val_loss: 0.2338 - val_accuracy: 0.9454\n",
      "Epoch 269/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0817 - accuracy: 0.9678 - val_loss: 0.2406 - val_accuracy: 0.9402\n",
      "Epoch 270/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0799 - accuracy: 0.9693 - val_loss: 0.2325 - val_accuracy: 0.9468\n",
      "Epoch 271/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0775 - accuracy: 0.9700 - val_loss: 0.2367 - val_accuracy: 0.9463\n",
      "Epoch 272/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0780 - accuracy: 0.9692 - val_loss: 0.2299 - val_accuracy: 0.9452\n",
      "Epoch 273/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0805 - accuracy: 0.9679 - val_loss: 0.2319 - val_accuracy: 0.9447\n",
      "Epoch 274/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9696 - val_loss: 0.2411 - val_accuracy: 0.9459\n",
      "Epoch 275/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0782 - accuracy: 0.9704 - val_loss: 0.2471 - val_accuracy: 0.9449\n",
      "Epoch 276/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0789 - accuracy: 0.9691 - val_loss: 0.2421 - val_accuracy: 0.9441\n",
      "Epoch 277/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0776 - accuracy: 0.9699 - val_loss: 0.2400 - val_accuracy: 0.9425\n",
      "Epoch 278/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0798 - accuracy: 0.9688 - val_loss: 0.2517 - val_accuracy: 0.9418\n",
      "Epoch 279/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9675 - val_loss: 0.2341 - val_accuracy: 0.9485\n",
      "Epoch 280/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0795 - accuracy: 0.9690 - val_loss: 0.2345 - val_accuracy: 0.9447\n",
      "Epoch 281/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0876 - accuracy: 0.9668 - val_loss: 0.2516 - val_accuracy: 0.9447\n",
      "Epoch 282/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0815 - accuracy: 0.9689 - val_loss: 0.2459 - val_accuracy: 0.9460\n",
      "Epoch 283/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0802 - accuracy: 0.9686 - val_loss: 0.2479 - val_accuracy: 0.9362\n",
      "Epoch 284/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0848 - accuracy: 0.9666 - val_loss: 0.2395 - val_accuracy: 0.9445\n",
      "Epoch 285/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9706 - val_loss: 0.2367 - val_accuracy: 0.9481\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 286/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0742 - accuracy: 0.9714 - val_loss: 0.2329 - val_accuracy: 0.9487\n",
      "Epoch 287/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0778 - accuracy: 0.9708 - val_loss: 0.2419 - val_accuracy: 0.9465\n",
      "Epoch 288/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9682 - val_loss: 0.2323 - val_accuracy: 0.9470\n",
      "Epoch 289/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0759 - accuracy: 0.9711 - val_loss: 0.2376 - val_accuracy: 0.9461\n",
      "Epoch 290/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0811 - accuracy: 0.9691 - val_loss: 0.2300 - val_accuracy: 0.9483\n",
      "Epoch 291/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0773 - accuracy: 0.9698 - val_loss: 0.2306 - val_accuracy: 0.9479\n",
      "Epoch 292/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0775 - accuracy: 0.9701 - val_loss: 0.2387 - val_accuracy: 0.9478\n",
      "Epoch 293/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9712 - val_loss: 0.2349 - val_accuracy: 0.9469\n",
      "Epoch 294/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0797 - accuracy: 0.9693 - val_loss: 0.2461 - val_accuracy: 0.9473\n",
      "Epoch 295/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0763 - accuracy: 0.9701 - val_loss: 0.2505 - val_accuracy: 0.9345\n",
      "Epoch 296/1000\n",
      "58/58 [==============================] - ETA: 0s - loss: 0.0831 - accuracy: 0.96 - 0s 7ms/step - loss: 0.0831 - accuracy: 0.9665 - val_loss: 0.2624 - val_accuracy: 0.9424\n",
      "Epoch 297/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0807 - accuracy: 0.9681 - val_loss: 0.2397 - val_accuracy: 0.9461\n",
      "Epoch 298/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0754 - accuracy: 0.9718 - val_loss: 0.2590 - val_accuracy: 0.9437\n",
      "Epoch 299/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0792 - accuracy: 0.9704 - val_loss: 0.2395 - val_accuracy: 0.9489\n",
      "Epoch 300/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0769 - accuracy: 0.9710 - val_loss: 0.2380 - val_accuracy: 0.9470\n",
      "Epoch 301/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0875 - accuracy: 0.9661 - val_loss: 0.2834 - val_accuracy: 0.9338\n",
      "Epoch 302/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0941 - accuracy: 0.9648 - val_loss: 0.2705 - val_accuracy: 0.9411\n",
      "Epoch 303/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0838 - accuracy: 0.9674 - val_loss: 0.2646 - val_accuracy: 0.9403\n",
      "Epoch 304/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0943 - accuracy: 0.9639 - val_loss: 0.2510 - val_accuracy: 0.9424\n",
      "Epoch 305/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0774 - accuracy: 0.9707 - val_loss: 0.2369 - val_accuracy: 0.9428\n",
      "Epoch 306/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0804 - accuracy: 0.9682 - val_loss: 0.2332 - val_accuracy: 0.9476\n",
      "Epoch 307/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9717 - val_loss: 0.2394 - val_accuracy: 0.9485\n",
      "Epoch 308/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0770 - accuracy: 0.9696 - val_loss: 0.2328 - val_accuracy: 0.9467\n",
      "Epoch 309/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0741 - accuracy: 0.9728 - val_loss: 0.2380 - val_accuracy: 0.9430\n",
      "Epoch 310/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0788 - accuracy: 0.9690 - val_loss: 0.2322 - val_accuracy: 0.9466\n",
      "Epoch 311/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0785 - accuracy: 0.9700 - val_loss: 0.2345 - val_accuracy: 0.9460\n",
      "Epoch 312/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0797 - accuracy: 0.9689 - val_loss: 0.2466 - val_accuracy: 0.9455\n",
      "Epoch 313/1000\n",
      "58/58 [==============================] - 0s 5ms/step - loss: 0.0803 - accuracy: 0.9688 - val_loss: 0.2298 - val_accuracy: 0.9489\n",
      "Epoch 314/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0727 - accuracy: 0.9724 - val_loss: 0.2416 - val_accuracy: 0.9467\n",
      "Epoch 315/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0814 - accuracy: 0.9677 - val_loss: 0.2400 - val_accuracy: 0.9470\n",
      "Epoch 316/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0755 - accuracy: 0.9708 - val_loss: 0.2406 - val_accuracy: 0.9459\n",
      "Epoch 317/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0756 - accuracy: 0.9713 - val_loss: 0.2378 - val_accuracy: 0.9424\n",
      "Epoch 318/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0814 - accuracy: 0.9684 - val_loss: 0.2316 - val_accuracy: 0.9486\n",
      "Epoch 319/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0771 - accuracy: 0.9702 - val_loss: 0.2383 - val_accuracy: 0.9469\n",
      "Epoch 320/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0768 - accuracy: 0.9706 - val_loss: 0.2447 - val_accuracy: 0.9464\n",
      "Epoch 321/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0765 - accuracy: 0.9708 - val_loss: 0.2438 - val_accuracy: 0.9453\n",
      "Epoch 322/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9715 - val_loss: 0.2485 - val_accuracy: 0.9476\n",
      "Epoch 323/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9711 - val_loss: 0.2340 - val_accuracy: 0.9494\n",
      "Epoch 324/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9678 - val_loss: 0.2376 - val_accuracy: 0.9483\n",
      "Epoch 325/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0771 - accuracy: 0.9706 - val_loss: 0.2381 - val_accuracy: 0.9467\n",
      "Epoch 326/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0733 - accuracy: 0.9722 - val_loss: 0.2349 - val_accuracy: 0.9477\n",
      "Epoch 327/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0728 - accuracy: 0.9731 - val_loss: 0.2488 - val_accuracy: 0.9477\n",
      "Epoch 328/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0735 - accuracy: 0.9715 - val_loss: 0.2491 - val_accuracy: 0.9360\n",
      "Epoch 329/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0794 - accuracy: 0.9685 - val_loss: 0.2460 - val_accuracy: 0.9475\n",
      "Epoch 330/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0749 - accuracy: 0.9714 - val_loss: 0.2359 - val_accuracy: 0.9491\n",
      "Epoch 331/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0737 - accuracy: 0.9708 - val_loss: 0.2546 - val_accuracy: 0.9456\n",
      "Epoch 332/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0765 - accuracy: 0.9704 - val_loss: 0.2427 - val_accuracy: 0.9478\n",
      "Epoch 333/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0766 - accuracy: 0.9710 - val_loss: 0.2523 - val_accuracy: 0.9469\n",
      "Epoch 334/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0741 - accuracy: 0.9714 - val_loss: 0.2715 - val_accuracy: 0.9416\n",
      "Epoch 335/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0760 - accuracy: 0.9706 - val_loss: 0.2398 - val_accuracy: 0.9449\n",
      "Epoch 336/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0805 - accuracy: 0.9689 - val_loss: 0.2366 - val_accuracy: 0.9470\n",
      "Epoch 337/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0758 - accuracy: 0.9711 - val_loss: 0.2813 - val_accuracy: 0.9408\n",
      "Epoch 338/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0810 - accuracy: 0.9694 - val_loss: 0.2892 - val_accuracy: 0.9430\n",
      "Epoch 339/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0825 - accuracy: 0.9683 - val_loss: 0.2499 - val_accuracy: 0.9469\n",
      "Epoch 340/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0811 - accuracy: 0.9695 - val_loss: 0.2590 - val_accuracy: 0.9460\n",
      "Epoch 341/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0801 - accuracy: 0.9704 - val_loss: 0.2718 - val_accuracy: 0.9426\n",
      "Epoch 342/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0816 - accuracy: 0.9684 - val_loss: 0.2416 - val_accuracy: 0.9467\n",
      "Epoch 343/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0764 - accuracy: 0.9705 - val_loss: 0.2449 - val_accuracy: 0.9476\n",
      "Epoch 344/1000\n",
      "58/58 [==============================] - 1s 11ms/step - loss: 0.0781 - accuracy: 0.9704 - val_loss: 0.2365 - val_accuracy: 0.9485\n",
      "Epoch 345/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0732 - accuracy: 0.9723 - val_loss: 0.2485 - val_accuracy: 0.9472\n",
      "Epoch 346/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0792 - accuracy: 0.9698 - val_loss: 0.2371 - val_accuracy: 0.9493\n",
      "Epoch 347/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0716 - accuracy: 0.9728 - val_loss: 0.2389 - val_accuracy: 0.9489\n",
      "Epoch 348/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0730 - accuracy: 0.9728 - val_loss: 0.2546 - val_accuracy: 0.9462\n",
      "Epoch 349/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0723 - accuracy: 0.9715 - val_loss: 0.2361 - val_accuracy: 0.9488\n",
      "Epoch 350/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0726 - accuracy: 0.9716 - val_loss: 0.2388 - val_accuracy: 0.9491\n",
      "Epoch 351/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0748 - accuracy: 0.9718 - val_loss: 0.2403 - val_accuracy: 0.9494\n",
      "Epoch 352/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9723 - val_loss: 0.2444 - val_accuracy: 0.9498\n",
      "Epoch 353/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0788 - accuracy: 0.9706 - val_loss: 0.2457 - val_accuracy: 0.9480\n",
      "Epoch 354/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0735 - accuracy: 0.9713 - val_loss: 0.2432 - val_accuracy: 0.9452\n",
      "Epoch 355/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0755 - accuracy: 0.9713 - val_loss: 0.2420 - val_accuracy: 0.9493\n",
      "Epoch 356/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0778 - accuracy: 0.9697 - val_loss: 0.2628 - val_accuracy: 0.9457\n",
      "Epoch 357/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0774 - accuracy: 0.9709 - val_loss: 0.2402 - val_accuracy: 0.9496\n",
      "Epoch 358/1000\n",
      "58/58 [==============================] - 0s 9ms/step - loss: 0.0737 - accuracy: 0.9718 - val_loss: 0.2435 - val_accuracy: 0.9485\n",
      "Epoch 359/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0779 - accuracy: 0.9700 - val_loss: 0.2665 - val_accuracy: 0.9449\n",
      "Epoch 360/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0763 - accuracy: 0.9711 - val_loss: 0.2610 - val_accuracy: 0.9324\n",
      "Epoch 361/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0778 - accuracy: 0.9699 - val_loss: 0.2728 - val_accuracy: 0.9440\n",
      "Epoch 362/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0761 - accuracy: 0.9703 - val_loss: 0.2307 - val_accuracy: 0.9496\n",
      "Epoch 363/1000\n",
      "58/58 [==============================] - 0s 6ms/step - loss: 0.0728 - accuracy: 0.9720 - val_loss: 0.2447 - val_accuracy: 0.9481\n",
      "Epoch 364/1000\n",
      "58/58 [==============================] - 0s 7ms/step - loss: 0.0760 - accuracy: 0.9711 - val_loss: 0.2518 - val_accuracy: 0.9406\n",
      "Epoch 365/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0874 - accuracy: 0.9657 - val_loss: 0.2417 - val_accuracy: 0.9466\n",
      "Epoch 366/1000\n",
      "58/58 [==============================] - 0s 8ms/step - loss: 0.0747 - accuracy: 0.9722 - val_loss: 0.2364 - val_accuracy: 0.9501\n",
      "\n",
      "Reached 95.00% accuracy, so stopping training!!\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(X_train, y_train, validation_split=0.25, batch_size=1000, epochs=1000, callbacks=[callback])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### have weight"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# fit model\n",
    "weights = {0:1, 1:55}\n",
    "history = model.fit(X_train, y_train, validation_split=0.25, batch_size=1000, epochs=1000)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test loss: 0.45460015535354614\n",
      "Test accuracy: 0.7861289381980896\n"
     ]
    }
   ],
   "source": [
    "# Evaluate the model with test data\n",
    "loss, accuracy = model.evaluate(X_test_3D, y_test, verbose=0)\n",
    "print('Test loss:', loss)\n",
    "print('Test accuracy:', accuracy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:Model was constructed with shape (None, 66) for input KerasTensor(type_spec=TensorSpec(shape=(None, 66), dtype=tf.float64, name='Normal1_input'), name='Normal1_input', description=\"created by layer 'Normal1_input'\"), but it was called on an input with incompatible shape (None, 1, 66).\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[[1.14225004e-10, 1.00000000e+00]],\n",
       "\n",
       "       [[3.13345785e-03, 9.96866524e-01]],\n",
       "\n",
       "       [[5.61080724e-02, 9.43891883e-01]],\n",
       "\n",
       "       ...,\n",
       "\n",
       "       [[1.87030293e-19, 1.00000000e+00]],\n",
       "\n",
       "       [[1.16055436e-10, 1.00000000e+00]],\n",
       "\n",
       "       [[9.94967878e-01, 5.03208628e-03]]], dtype=float32)"
      ]
     },
     "execution_count": 285,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_3D)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\User\\AppData\\Roaming\\Python\\Python37\\site-packages\\tensorflow\\python\\keras\\engine\\sequential.py:450: UserWarning: `model.predict_classes()` is deprecated and will be removed after 2021-01-01. Please use instead:* `np.argmax(model.predict(x), axis=-1)`,   if your model does multi-class classification   (e.g. if it uses a `softmax` last-layer activation).* `(model.predict(x) > 0.5).astype(\"int32\")`,   if your model does binary classification   (e.g. if it uses a `sigmoid` last-layer activation).\n",
      "  warnings.warn('`model.predict_classes()` is deprecated and '\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1],\n",
       "       [1],\n",
       "       [1],\n",
       "       ...,\n",
       "       [1],\n",
       "       [1],\n",
       "       [0]], dtype=int64)"
      ]
     },
     "execution_count": 286,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 計算『混淆矩陣』(Confusion Matrix)，顯示測試集分類的正確及錯認總和數\n",
    "predictions = model.predict_classes(X_test_3D) \n",
    "predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[8848  725]\n",
      " [ 203 9516]]\n"
     ]
    }
   ],
   "source": [
    "#利用confusion matrix來看實際及預測的差異\n",
    "confu_matrix = confusion_matrix(y_test_org,predictions)\n",
    "print(confu_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           0       0.98      0.92      0.95      9573\n",
      "           1       0.93      0.98      0.95      9719\n",
      "\n",
      "    accuracy                           0.95     19292\n",
      "   macro avg       0.95      0.95      0.95     19292\n",
      "weighted avg       0.95      0.95      0.95     19292\n",
      "\n"
     ]
    }
   ],
   "source": [
    "#利用classification report來看precision、recall、f1-score、support\n",
    "print(classification_report(y_test_org,predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tp:  8848\n",
      "fp:  725\n",
      "fn:  203\n",
      "tn:  9516\n",
      "tpr:  0.9775715390564579\n",
      "fpr:  0.070793867786349\n",
      "---------------------\n",
      "acc:  0.9518971594443293\n",
      "f1:  0.9501718213058419\n",
      "ppv:  0.9242661652564504\n",
      "recall:  0.9775715390564579\n",
      "mcc:  0.9050768619292447\n",
      "auc:  0.9533888356350544\n"
     ]
    }
   ],
   "source": [
    "import math\n",
    "\n",
    "\n",
    "#      |  (a)  |  (b)  |\n",
    "# --------------------------\n",
    "# (a)  |  TP   |  FP   |\n",
    "# --------------------------\n",
    "# (b)  |  FN   |  TN   |\n",
    "\n",
    "# fp, tn, fn, tp = confu_matrix.ravel()\n",
    "tp = confu_matrix[0, 0]\n",
    "fp = confu_matrix[0, 1]\n",
    "fn = confu_matrix[1, 0]\n",
    "tn = confu_matrix[1, 1]\n",
    "\n",
    "acc = (tp + tn) / (tp + fp + tn + fn)\n",
    "f1 = (2 * tp) / (2 * tp + fp + fn)\n",
    "ppv = (tp) / (tp + fp)\n",
    "recall = (tp) / (tp + fn)\n",
    "mcc = ((tp * tn) - (fp * fn)) / (math.sqrt((tp + fp) * (tp + fn) * (tn + fp) * (tn + fn)))\n",
    "\n",
    "tpr = tp / (tp + fn)\n",
    "fpr = fp / (fp + tn) \n",
    "auc = 1/2 - fpr/2 + tpr/2\n",
    "\n",
    "print('tp: ', tp)\n",
    "print('fp: ', fp)\n",
    "print('fn: ', fn)\n",
    "print('tn: ', tn)\n",
    "print('tpr: ', tpr)\n",
    "print('fpr: ', fpr)\n",
    "print('---------------------')\n",
    "print('acc: ', acc)\n",
    "print('f1: ', f1)\n",
    "print('ppv: ', ppv)\n",
    "print('recall: ', recall)\n",
    "print('mcc: ', mcc)\n",
    "print('auc: ', auc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "y_pred_keras = model.predict(X_test).ravel()\n",
    "fpr_keras, tpr_keras, thresholds_keras = roc_curve(y_test_org, predictions)\n",
    "print('fpr_keras: ', fpr_keras)\n",
    "print('tpr_keras: ', tpr_keras)\n",
    "print('thresholds_keras: ', thresholds_keras)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Actual: [0 1 1 1 1 0 0 0 0 1 0 0 0 0 1 0 0 1 0 0 1 1 0 0 1 1 0 1 1 0 0 1 1 1 1 0 1\n",
      " 0 0 0 0 1 1 0 0 0 0 0 1 0 1 1 1 0 0 1 1 0 1 0 0 0 1 1 1 1 0 0 1 1 1 0 0 1\n",
      " 0 1 0 0 1 1 1 1 1 1 0 0 0 0 0 0 0 0 1 0 1 0 0 1 0 1 1 1 1 0 1 1 1 1 1 0 1\n",
      " 0 1 1 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 0 1 0 1 1 0 0 1 0 1 1 1 0 0 0 0 1 1 1\n",
      " 1 0 0 0 0 1 0 0 1 1 0 0 0 1 0 0 0 0 1 1 0 1 1 1 1 1 1 0 0 1 0 1 0 1 0 1 0\n",
      " 1 0 0 0 0 0 0 0 1 0 0 1 0 1 1 0 1 0 0 1 0 1 1 0 0 1 0 1 1 1 0 1 0 0 1 1 0\n",
      " 1 0 0 1 1 1 0 1 1 1 1 1 0 1 0 0 0 1 1 0 1 1 0 0 0 1 1 1 1 0 0 0 1 0 0 0 1\n",
      " 0 1 1 1 0 0 0 1 0 1 1 1 0 0 1 0 0 1 1 0 0 1 1 1 0 1 0 1 0 0 1 0 1 1 0 0 0\n",
      " 0 0 1 1 0 1 1 0 0 0 1 0 0 1 1 0 0 1 1 0 1 0 0 1 0 1 0 1 1 0 1 0 0 0 1 0 0\n",
      " 1 1 0 0 0 0 1 1 1 1 1 1 0 1 1 0]\n",
      "Predicted: [0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0\n",
      " 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0 0]\n"
     ]
    }
   ],
   "source": [
    "actual = np.argmax(y_test,axis=1)\n",
    "predicted = np.argmax(y_pred,axis=1)\n",
    "print(f\"Actual: {actual}\")\n",
    "print(f\"Predicted: {predicted}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 318,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5"
      ]
     },
     "execution_count": 318,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import auc\n",
    "auc_keras = auc(fpr_keras, tpr_keras)\n",
    "auc_keras"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 319,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-0.015955383216590315"
      ]
     },
     "execution_count": 319,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import matthews_corrcoef\n",
    "matthews_corrcoef(y_test_org, predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 320,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.024725274725274724"
      ]
     },
     "execution_count": 320,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import precision_score\n",
    "precision_score(y_test_org, predictions, average='micro')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## save model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 將模型儲存至 HDF5 檔案中\n",
    "model.save('./model/cnn/CNNmodel_BSET' + preprocess_status + '.h5')  # creates a HDF5 file 'my_model.h5'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 可視化"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_35\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "Normal1 (Normalization)      (None, 66)                133       \n",
      "_________________________________________________________________\n",
      "Dense1 (Dense)               (None, 256)               17152     \n",
      "_________________________________________________________________\n",
      "ReLU1 (ReLU)                 (None, 256)               0         \n",
      "_________________________________________________________________\n",
      "Dense2 (Dense)               (None, 32)                8224      \n",
      "_________________________________________________________________\n",
      "ReLU2 (ReLU)                 (None, 32)                0         \n",
      "_________________________________________________________________\n",
      "Dense3 (Dense)               (None, 2)                 66        \n",
      "=================================================================\n",
      "Total params: 25,575\n",
      "Trainable params: 25,442\n",
      "Non-trainable params: 133\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製訓練 & 驗證的準確率值\n",
    "plt.plot(history.history['accuracy'])\n",
    "plt.plot(history.history['val_accuracy'])\n",
    "plt.title('Model accuracy')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# 繪製訓練 & 驗證的損失值\n",
    "plt.plot(history.history['loss'])\n",
    "plt.plot(history.history['val_loss'])\n",
    "plt.title('Model loss')\n",
    "plt.ylabel('Loss')\n",
    "plt.xlabel('Epoch')\n",
    "plt.legend(['Train', 'Test'], loc='upper left')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:>"
      ]
     },
     "execution_count": 180,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 720x504 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sn\n",
    "df_cm = pd.DataFrame(confu_matrix, index = [i for i in \"01\"],\n",
    "                  columns = [i for i in \"01\"])\n",
    "plt.figure(figsize = (10,7))\n",
    "sn.heatmap(df_cm, fmt = \".20g\", annot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
